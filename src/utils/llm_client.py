"""
LLM Client with Retry Logic & Error Handling
Provides resilient LLM execution with exponential backoff and circuit breaker.
"""
import asyncio
import random
from typing import TypeVar, Any
from loguru import logger
from pydantic_ai import Agent
from src.config import get_settings
from src.utils.circuit_breaker import get_openai_circuit, CircuitState

# Type variable for generic agent output
T = TypeVar('T')


class LLMError(Exception):
    """Recoverable LLM errors that should trigger retries."""
    pass


class LLMCriticalError(Exception):
    """Non-recoverable errors (auth failure, invalid prompt, etc.)."""
    pass


async def run_agent_with_retry(
    agent: Agent,
    prompt: str,
    deps: Any = None,
    max_retries: int | None = None
) -> T:
    """
    Executes an agent with exponential backoff retry logic.

    Args:
        agent: The PydanticAI agent to run
        prompt: The prompt to send to the agent
        deps: Optional dependencies for the agent
        max_retries: Override default retry count from settings

    Returns:
        The agent's output (typed based on agent's output_type)

    Raises:
        LLMCriticalError: For non-recoverable failures
        LLMError: After max retries exhausted

    Example:
        >>> agent = Agent('openai:gpt-4o', output_type=MyResponse)
        >>> result = await run_agent_with_retry(agent, "Classify this")
        >>> print(result.intent)
    """
    settings = get_settings()
    max_attempts = max_retries or settings.max_retries
    min_wait = settings.retry_min_wait_seconds
    max_wait = settings.retry_max_wait_seconds

    last_error = None

    for attempt in range(1, max_attempts + 1):
        try:
            logger.debug(f"LLM attempt {attempt}/{max_attempts}")

            # Execute the agent
            if deps is not None:
                result = await agent.run(prompt, deps=deps)
            else:
                result = await agent.run(prompt)

            return result.output

        except Exception as e:
            last_error = e
            error_msg = str(e).lower()

            # Categorize the error
            if "rate" in error_msg and "limit" in error_msg:
                logger.warning(f"â±ï¸ Rate limit hit (attempt {attempt}/{max_attempts})")
                error_type = "rate_limit"

            elif "timeout" in error_msg or "timed out" in error_msg:
                logger.warning(f"â±ï¸ Timeout (attempt {attempt}/{max_attempts})")
                error_type = "timeout"

            elif any(code in error_msg for code in ["500", "502", "503", "504"]):
                logger.warning(f"ðŸ”§ Server error (attempt {attempt}/{max_attempts})")
                error_type = "server_error"

            elif "authentication" in error_msg or "api key" in error_msg or "401" in error_msg:
                logger.error(f"ðŸš¨ Authentication failure: {e}")
                raise LLMCriticalError(f"Authentication failed: {e}") from e

            elif "invalid" in error_msg and "request" in error_msg:
                logger.error(f"ðŸš¨ Invalid request: {e}")
                raise LLMCriticalError(f"Invalid request: {e}") from e

            else:
                # Unknown error - treat as recoverable but log it
                logger.warning(f"âš ï¸ Unknown error (attempt {attempt}/{max_attempts}): {e}")
                error_type = "unknown"

            # If this was the last attempt, raise
            if attempt == max_attempts:
                logger.error(f"âŒ Max retries ({max_attempts}) exhausted. Last error: {e}")
                raise LLMError(f"Failed after {max_attempts} attempts: {e}") from e

            # Calculate exponential backoff with jitter
            wait_time = min(min_wait * (2 ** (attempt - 1)), max_wait)
            # Add 20% jitter to prevent thundering herd
            wait_time = wait_time * (0.8 + 0.4 * random.random())

            logger.info(f"â³ Retrying in {wait_time:.1f}s... (error: {error_type})")
            await asyncio.sleep(wait_time)

    # Should never reach here, but just in case
    raise LLMError(f"Unexpected retry loop exit. Last error: {last_error}")


async def run_agent_with_fallback(
    agent: Agent,
    prompt: str,
    fallback_factory: callable,
    deps: Any = None
) -> T:
    """
    Executes an agent with a fallback response if all retries fail.

    Useful for agents where a degraded response is better than total failure.

    Args:
        agent: The PydanticAI agent to run
        prompt: The prompt to send to the agent
        fallback_factory: Function that returns a safe default response
        deps: Optional dependencies for the agent

    Returns:
        Either the agent's output or the fallback response

    Example:
        >>> def safe_classification():
        >>>     return ClassifierResponse(intent=Intent.UNCLEAR, ...)
        >>> result = await run_agent_with_fallback(agent, prompt, safe_classification)
    """
    try:
        return await run_agent_with_retry(agent, prompt, deps=deps)
    except (LLMError, LLMCriticalError) as e:
        logger.error(f"ðŸ›Ÿ LLM failed, using fallback response: {e}")
        return fallback_factory()


async def run_agent_with_circuit_breaker(
    agent: Agent,
    prompt: str,
    fallback_factory: callable,
    deps: Any = None
) -> T:
    """
    Executes an agent with circuit breaker protection.

    Combines retry logic with circuit breaker pattern for graceful degradation.
    When OpenAI is experiencing issues, the circuit opens and returns fallback
    responses immediately without wasting API calls.

    Args:
        agent: The PydanticAI agent to run
        prompt: The prompt to send to the agent
        fallback_factory: Function that returns a safe default response
        deps: Optional dependencies for the agent

    Returns:
        Either the agent's output or the fallback response

    Example:
        >>> def safe_response():
        >>>     return ExecutorResponse(message="I'll get back to you shortly.")
        >>> result = await run_agent_with_circuit_breaker(agent, prompt, safe_response)
    """
    circuit = get_openai_circuit()

    async def execute():
        return await run_agent_with_retry(agent, prompt, deps=deps)

    return await circuit.call_with_fallback(execute, fallback_factory)


def get_circuit_status() -> dict:
    """Get current circuit breaker status for monitoring."""
    return get_openai_circuit().get_status()


def is_circuit_open() -> bool:
    """Check if circuit breaker is currently open."""
    return get_openai_circuit().state == CircuitState.OPEN
